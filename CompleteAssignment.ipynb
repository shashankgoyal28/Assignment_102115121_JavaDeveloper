{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install PyMuPDF pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRmxeyvTo04d",
        "outputId": "b45fd787-43e0-4966-b5dc-49580cc3a485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_tables_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts tables from a PDF file.\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "    Returns:\n",
        "        list: List of tables, where each table is a list of rows.\n",
        "    \"\"\"\n",
        "    # Opens the PDF file\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    tables = []\n",
        "\n",
        "    # Iterating through each page\n",
        "    for page_num in range(len(pdf_document)):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        words = page.get_text(\"words\")  # Extract words with their coordinates\n",
        "\n",
        "        # Grouping the words into lines based on their y-coordinates\n",
        "        lines = {}\n",
        "        for word in words:\n",
        "            x0, y0, x1, y1, word_text, block_no, line_no, word_no = word\n",
        "            if y0 not in lines:\n",
        "                lines[y0] = []\n",
        "            lines[y0].append((x0, word_text))\n",
        "\n",
        "        # Sorting lines by y-coordinate\n",
        "        sorted_lines = sorted(lines.items(), key=lambda x: x[0])\n",
        "\n",
        "        # Converting lines into a table structure\n",
        "        table = []\n",
        "        for _, line_words in sorted_lines:\n",
        "            # Sorting words in the line by x-coordinate\n",
        "            sorted_words = sorted(line_words, key=lambda x: x[0])\n",
        "            row = [word[1] for word in sorted_words]\n",
        "            table.append(row)\n",
        "\n",
        "        # Adds the table to the list of tables\n",
        "        if table:\n",
        "            tables.append(table)\n",
        "\n",
        "    return tables\n",
        "\n",
        "def save_tables_to_csv(tables, output_csv_folder):\n",
        "    \"\"\"\n",
        "    Saves extracted tables to CSV files.\n",
        "    Args: tables (list): List of tables, where each table is a list of rows. output_csv_folder (str): Path to the folder where CSV files will be saved.\n",
        "    \"\"\"\n",
        "    # Createing the output folder if it doesn't exist already\n",
        "    if not os.path.exists(output_csv_folder):\n",
        "        os.makedirs(output_csv_folder)\n",
        "\n",
        "    # Saveing each table as a separate CSV file\n",
        "    for i, table in enumerate(tables):\n",
        "        # Converting the table to a pandas DataFrame\n",
        "        df = pd.DataFrame(table)\n",
        "        # Saveing the DataFrame to a CSV file\n",
        "        csv_path = os.path.join(output_csv_folder, f\"Table_{i+1}.csv\")\n",
        "        df.to_csv(csv_path, index=False, header=False)\n",
        "        print(f\"Table {i+1} saved to {csv_path}\")\n",
        "\n",
        "def main(pdf_path, output_csv_folder):\n",
        "    \"\"\"\n",
        "    Main function to extract tables from a PDF and save them to CSV files.\n",
        "    Args:\n",
        "        pdf_path (str): Path to the input PDF file.\n",
        "        output_csv_folder (str): Path to save the output CSV files.\n",
        "    \"\"\"\n",
        "    # Extract tables from the PDF\n",
        "    tables = extract_tables_from_pdf(pdf_path)\n",
        "    # Save the tables to CSV files\n",
        "    save_tables_to_csv(tables, output_csv_folder)\n",
        "    print(f\"Tables extracted and saved to {output_csv_folder}\")\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"test3.pdf\"  # PDF file path\n",
        "output_csv_folder = \"output_csv\"  # CSV files\n",
        "main(pdf_path, output_csv_folder)"
      ],
      "metadata": {
        "id": "bXMsStcJwOZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7463472-b131-4dcf-caf9-f30f984f43b4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 1 saved to output_csv/Table_1.csv\n",
            "Table 2 saved to output_csv/Table_2.csv\n",
            "Table 3 saved to output_csv/Table_3.csv\n",
            "Table 4 saved to output_csv/Table_4.csv\n",
            "Table 5 saved to output_csv/Table_5.csv\n",
            "Table 6 saved to output_csv/Table_6.csv\n",
            "Table 7 saved to output_csv/Table_7.csv\n",
            "Table 8 saved to output_csv/Table_8.csv\n",
            "Tables extracted and saved to output_csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Part\n"
      ],
      "metadata": {
        "id": "F99gtrWmbWP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def calculate_accuracy(extracted_tables, reference_folder):\n",
        "    \"\"\"\n",
        "    Compares extracted tables with manually verified reference tables to calculate accuracy.\n",
        "\n",
        "    Args:\n",
        "        extracted_tables (list): List of extracted tables (each table is a list of rows).\n",
        "        reference_folder (str): Path to the folder containing manually verified reference CSV files.\n",
        "\n",
        "    Returns:\n",
        "        dict: Accuracy metrics (cell-level, row-level, table-level).\n",
        "    \"\"\"\n",
        "    total_cells = 0\n",
        "    correct_cells = 0\n",
        "    total_rows = 0\n",
        "    correct_rows = 0\n",
        "    total_tables = len(extracted_tables)\n",
        "    correct_tables = 0\n",
        "\n",
        "    for i, extracted_table in enumerate(extracted_tables):\n",
        "        csv_path = os.path.join(reference_folder, f\"Table_{i+1}.csv\")\n",
        "\n",
        "        if not os.path.exists(csv_path):\n",
        "            print(f\"Reference file {csv_path} not found. Skipping comparison for this table.\")\n",
        "            continue\n",
        "\n",
        "        # Load reference table\n",
        "        reference_df = pd.read_csv(csv_path, header=None)\n",
        "        extracted_df = pd.DataFrame(extracted_table)\n",
        "\n",
        "        # Convert both DataFrames to string format for direct comparison\n",
        "        reference_values = reference_df.astype(str).values\n",
        "        extracted_values = extracted_df.astype(str).values\n",
        "\n",
        "        # Get table dimensions\n",
        "        ref_rows, ref_cols = reference_values.shape\n",
        "        ext_rows, ext_cols = extracted_values.shape\n",
        "\n",
        "        # Ensure shape consistency by padding with empty strings\n",
        "        max_rows = max(ref_rows, ext_rows)\n",
        "        max_cols = max(ref_cols, ext_cols)\n",
        "        padded_reference = [[\"\"] * max_cols for _ in range(max_rows)]\n",
        "        padded_extracted = [[\"\"] * max_cols for _ in range(max_rows)]\n",
        "\n",
        "        for r in range(ref_rows):\n",
        "            for c in range(ref_cols):\n",
        "                padded_reference[r][c] = reference_values[r][c]\n",
        "\n",
        "        for r in range(ext_rows):\n",
        "            for c in range(ext_cols):\n",
        "                padded_extracted[r][c] = extracted_values[r][c]\n",
        "\n",
        "        # cell-level\n",
        "        for r in range(max_rows):\n",
        "            for c in range(max_cols):\n",
        "                total_cells += 1\n",
        "                if padded_reference[r][c] == padded_extracted[r][c]:\n",
        "                    correct_cells += 1\n",
        "\n",
        "        # row-level\n",
        "        for r in range(max_rows):\n",
        "            total_rows += 1\n",
        "            if padded_reference[r] == padded_extracted[r]:\n",
        "                correct_rows += 1\n",
        "\n",
        "        #table-level\n",
        "        if reference_df.shape == extracted_df.shape and reference_df.equals(extracted_df):\n",
        "            correct_tables += 1\n",
        "\n",
        "    cell_accuracy = correct_cells / total_cells * 100 if total_cells else 0\n",
        "    row_accuracy = correct_rows / total_rows * 100 if total_rows else 0\n",
        "    table_accuracy = correct_tables / total_tables * 100 if total_tables else 0\n",
        "\n",
        "    accuracy_metrics = {\n",
        "        \"Cell-Level Accuracy\": f\"{cell_accuracy:.2f}%\",\n",
        "        \"Row-Level Accuracy\": f\"{row_accuracy:.2f}%\",\n",
        "        \"Table-Level Accuracy\": f\"{table_accuracy:.2f}%\"\n",
        "    }\n",
        "\n",
        "    return accuracy_metrics"
      ],
      "metadata": {
        "id": "2qqqQONIcQpq"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}